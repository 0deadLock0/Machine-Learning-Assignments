{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import matplotlib.pyplot\n",
    "import sklearn.neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(folder_name) :\n",
    "\t\"\"\"\n",
    "\tPreproccess the raw data for easy/better use\n",
    "\tInput Paramteres :\n",
    "\t\tfile_name_with_relative_path - name of file from which contains data\n",
    "\tReturn Values :\n",
    "\t\tx - features\n",
    "\t\ty - target value\n",
    "\t\"\"\"\n",
    "\n",
    "\ttrain_df = pandas.read_csv(folder_name + '/mnist_train.csv')\n",
    "\ttest_df = pandas.read_csv(folder_name + '/mnist_test.csv')\n",
    "\n",
    "\tdata_df = train_df.append(test_df).reset_index(drop = True)\n",
    "\tdata_df = data_df.sample(frac = 0.05).reset_index(drop = True)\n",
    "\n",
    "\ty = data_df['label'].to_numpy()\n",
    "\tx = data_df.drop('label', axis = 1).to_numpy()\n",
    "\n",
    "\ty = y.reshape((y.shape[0], -1))\n",
    "\n",
    "\treturn (x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(features, target, train_ratio, val_ratio, test_ratio) :\n",
    "\t\"\"\"\n",
    "\tSplits the dataset into training, validation and testing\n",
    "\tInput Parameters:\n",
    "\t\tfeatures - features columns of dataset\n",
    "\t\ttarget - target columns of dataset\n",
    "\t\ttrain_ratio - the ratio of split for training set\n",
    "\t\tval_ratio - the ratio of split for validation set\n",
    "\t\ttest_ratio - the ratio of split for testing set\n",
    "\tReturn Values:\n",
    "\t\ttrain_set - a two tuple containing features and target of training set\n",
    "\t\tval_set - a two tuple containing features and target of validation set\n",
    "\t\ttest_set - a two tuple containing features and target of testing set\n",
    "\t\"\"\"\n",
    "\n",
    "\tenteries_count = features.shape[0]\n",
    "\ttrain_size = int( enteries_count * train_ratio )\n",
    "\tval_size = int( enteries_count * val_ratio )\n",
    "\n",
    "\tval_index_l = train_size\n",
    "\tval_index_r = train_size + val_size\n",
    "\n",
    "\tindexes = numpy.arange(enteries_count)\n",
    "\tnumpy.random.shuffle(indexes)\n",
    "\n",
    "\t# split data into train/test sets\n",
    "\ttrain_set = (features[indexes[ : train_size]], target[indexes[ : train_size]])\n",
    "\tval_set = (features[indexes[ val_index_l : val_index_r ]], target[indexes[ val_index_l : val_index_r ]])\n",
    "\ttest_set = (features[indexes[ val_index_r : ]], target[indexes[ val_index_r : ]])\n",
    "\n",
    "\t# print(features.shape[0], train_set[0].shape[0], val_set[0].shape[0], test_set[0].shape[0])\n",
    "\n",
    "\treturn (train_set, val_set, test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNetwork():\n",
    "\n",
    "\tdef __init__(self, n_layers, layer_sizes, activation, learning_rate, weight_init, batch_size, num_epochs):\n",
    "\t\t\"\"\"\n",
    "\t\tInitialise all class attributes\n",
    "\t\tInput Parameters -\n",
    "\t\t\tn_layers : Number of layers (int)\n",
    "\t\t\tlayer_sizes : array of size n_layers which contains the number of nodes in each layer (array of int)\n",
    "\t\t\tactivation : Activation function to be used (string) ['relu', 'leaky relu' 'sigmoid', 'linear', 'tanh', 'softmax']\n",
    "\t\t\tlearning_rate : the learning rate to be used (float)\n",
    "\t\t\tweight_init : initialization function to be used (string) [zero, random, normal]\n",
    "\t\t\tbatch_size : batch size to be used (int)\n",
    "\t\t\tnum_epochs : number of epochs to be used (int)\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tself.n_layers = n_layers\n",
    "\t\tself.layer_sizes = layer_sizes\n",
    "\t\tself.activation = activation\n",
    "\t\tself.learning_rate = learning_rate\n",
    "\t\tself.weight_init = weight_init\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.num_epochs = num_epochs\n",
    "\n",
    "\t\tself.weights = [ self.weight_function((self.layer_sizes[i], self.layer_sizes[i+1])) for i in range(self.n_layers - 1) ]\n",
    "\t\tself.biases = [ numpy.zeros(self.layer_sizes[i+1]) for i in range(self.n_layers - 1) ]\n",
    "\n",
    "\t\tself.training_loss = numpy.zeros(self.num_epochs)\n",
    "\t\tself.validation_loss = numpy.zeros(self.num_epochs)\n",
    "\n",
    "\tdef weight_function(self, shape) :\n",
    "\t\t\"\"\"\n",
    "\t\tReturns a numpy array of given shape with values initialised as per chosen option\n",
    "\t\tInput Parameters:\n",
    "\t\t\tshape - shape of array\n",
    "\t\tOutput Parameters:\n",
    "\t\t\ta numpy array of given shape\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif self.weight_init == \"zero\" :\n",
    "\t\t\treturn self.zero_init(shape)\n",
    "\t\telif self.weight_init == \"random\" :\n",
    "\t\t\treturn self.random_init(shape)\n",
    "\t\telif self.weight_init == \"normal\" :\n",
    "\t\t\treturn self.normal_init(shape)\n",
    "\t\telse :\n",
    "\t\t\traise Exception('Incorrect Weight Initialisation Function')\n",
    "\n",
    "\tdef zero_init(self, shape) :\n",
    "\t\t\"\"\"\n",
    "\t\tGenerates a numpy array of given shape with all values zero\n",
    "\t\tInput Parameters:\n",
    "\t\t\tshape - shape of array\n",
    "\t\tOutput Parameters:\n",
    "\t\t\tweights - a zero filled numpy array of given shape\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tweights = numpy.zeros(shape)\n",
    "\n",
    "\t\treturn weights\n",
    "\n",
    "\tdef random_init(self, shape) :\n",
    "\t\t\"\"\"\n",
    "\t\tGenerates a numpy array of given shape filled with random values\n",
    "\t\tInput Parameters:\n",
    "\t\t\tshape - shape of array\n",
    "\t\tOutput Parameters:\n",
    "\t\t\tweights - a randomly filled numpy array of given shape\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tscaling_factor = 0.01 \n",
    "\t\tweights = numpy.random.random_sample(shape) * scaling_factor\n",
    "\n",
    "\t\treturn weights\n",
    "\t\n",
    "\tdef normal_init(self, shape) :\n",
    "\t\t\"\"\"\n",
    "\t\tGenerates a numpy array of having normal \n",
    "\t\tInput Parameters:\n",
    "\t\t\tshape - shape of array\n",
    "\t\tOutput Parameters:\n",
    "\t\t\tweights - a randomly filled numpy array of given shape\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tscaling_factor = 0.01\n",
    "\t\tweights = numpy.random.normal(size = shape) * scaling_factor\n",
    "\n",
    "\t\treturn weights\n",
    "\t\n",
    "\tdef activation_fuction_with_derivative(self, v) :\n",
    "\t\t\"\"\"\n",
    "\t\tCaclculates the activation value and its derivative for given value\n",
    "\t\tInput Parameters:\n",
    "\t\t\tv - value for which activation value and derivative is required\n",
    "\t\tOutput Parameters:\n",
    "\t\t\tactivation value, activation value's derivative\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t# ['relu', 'leaky relu' 'sigmoid', 'linear', 'tanh', 'softmax']\n",
    "\t\tif self.activation == \"relu\" :\n",
    "\t\t\treturn self.relu(v)\n",
    "\t\telif self.activation == \"leaky relu\" :\n",
    "\t\t\treturn self.leaky_relu(v)\n",
    "\t\telif self.activation == \"sigmoid\" :\n",
    "\t\t\treturn self.sigmoid(v)\n",
    "\t\telif self.activation == \"linear\" :\n",
    "\t\t\treturn self.linear(v)\n",
    "\t\telif self.activation == \"tanh\" :\n",
    "\t\t\treturn self.tanh(v)\n",
    "\t\telif self.activation == \"softmax\" :\n",
    "\t\t\treturn self.softmax(v)\n",
    "\t\telse :\n",
    "\t\t\traise Exception('Incorrect Activation Function')\n",
    "\n",
    "\tdef relu(self, v) :\n",
    "\t\t\"\"\"\n",
    "\t\tCaclculates the relu activation value and its derivative for given value\n",
    "\t\tInput Parameters:\n",
    "\t\t\tv - value for which activation value and derivative is required\n",
    "\t\tOutput Parameters:\n",
    "\t\t\ty - relu activation value\n",
    "\t\t\td_phi - derivative of relu activation at v\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\ty = numpy.where(v >= 0, v, 0)\n",
    "\t\td_phi = numpy.where(v >= 0, 1, 0)\n",
    "\n",
    "\t\treturn (y, d_phi)\n",
    "\n",
    "\n",
    "\tdef leaky_relu(self, v) :\n",
    "\t\t\"\"\"\n",
    "\t\tCaclculates the leaky relu activation value and its derivative for given value\n",
    "\t\tInput Parameters:\n",
    "\t\t\tv - value for which activation value and derivative is required\n",
    "\t\tOutput Parameters:\n",
    "\t\t\ty - leaky relu activation value\n",
    "\t\t\td_phi - derivative of leaky relu activation at v\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\talpha = 0.1\n",
    "\t\ty = numpy.where(v >= 0, v, alpha * v)\n",
    "\t\td_phi = numpy.where(v >= 0, 1, alpha)\n",
    "\n",
    "\t\treturn (y, d_phi)\n",
    "\n",
    "\tdef sigmoid(self, v) :\n",
    "\t\t\"\"\"\n",
    "\t\tCaclculates the sigmoid activation value and its derivative for given value\n",
    "\t\tInput Parameters:\n",
    "\t\t\tv - value for which activation value and derivative is required\n",
    "\t\tOutput Parameters:\n",
    "\t\t\ty - sigmoid activation value\n",
    "\t\t\td_phi - derivative of sigmoid activation at v\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\ty = 1 / (1 + numpy.exp(-v))\n",
    "\t\td_phi = y * (1 - y)\n",
    "\n",
    "\t\treturn (y, d_phi)\n",
    "\n",
    "\tdef linear(self, v) :\n",
    "\t\t\"\"\"\n",
    "\t\tCaclculates the linear activation value and its derivative for given value\n",
    "\t\tInput Parameters:\n",
    "\t\t\tv - value for which activation value and derivative is required\n",
    "\t\tOutput Parameters:\n",
    "\t\t\ty - linear activation value\n",
    "\t\t\td_phi - derivative of linear activation at v\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\ty = v\n",
    "\t\td_phi = numpy.ones(v.shape)\n",
    "\n",
    "\t\treturn (y, d_phi)\n",
    "\n",
    "\tdef tanh(self, v) :\n",
    "\t\t\"\"\"\n",
    "\t\tCaclculates the tanh activation value and its derivative for given value\n",
    "\t\tInput Parameters:\n",
    "\t\t\tv - value for which activation value and derivative is required\n",
    "\t\tOutput Parameters:\n",
    "\t\t\ty - tanh activation value\n",
    "\t\t\td_phi - derivative of tanh activation at v\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\ty = numpy.tanh(v)\n",
    "\t\td_phi = 1 - numpy.square(y)\n",
    "\t\t\n",
    "\t\treturn (y, d_phi)\n",
    "\n",
    "\tdef softmax(self, v) :\n",
    "\t\t\"\"\"\n",
    "\t\tCaclculates the tanh activation value and its derivative for given value\n",
    "\t\tInput Parameters:\n",
    "\t\t\tv - value for which activation value and derivative is required\n",
    "\t\tOutput Parameters:\n",
    "\t\t\ty - softmax activation value\n",
    "\t\t\td_phi - derivative of softmax activation at v\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tv -= numpy.max(v)\n",
    "\t\tt = numpy.exp(v)\n",
    "\t\ty = t / ( t.sum(axis=1, keepdims = True) )\n",
    "\n",
    "\t\td_phi = None\n",
    "\n",
    "\t\treturn (y, d_phi)\n",
    "\n",
    "\tdef cross_entropy_loss(self, y_true, y_pred_prob):\n",
    "\t\t\"\"\"\n",
    "\t\tCalculates the cross entropy loss from true target and calculated probabilites of predictions\n",
    "\t\tInput Parameters:\n",
    "\t\t\ty_true - true values of targets\n",
    "\t\t\ty_pred_prob - probability of predicitions\n",
    "\t\tOutput Parameters:\n",
    "\t\t\tloss - calculated cross entropy loss\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tsum_score = 10**(-9)\n",
    "        \n",
    "\t\tfor i in range(y_true.shape[0]):\n",
    "\t\t\tsum_score += y_true[i] * numpy.log( 1e-15  +  y_pred_prob[i])\n",
    "\t\tloss = 1.0 / y_true.shape[0] * sum_score\n",
    "\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef fit(self, train_set, val_set = None):\n",
    "\t\t\"\"\"\n",
    "\t\tFits the model using given training data\n",
    "\t\tInput Parameters:\n",
    "\t\t\ttrain_set - training data, a tuple of features and target\n",
    "\t\t\tval_set - validation data, a tuple of features and target\n",
    "\t\tOutput Parameters:\n",
    "\t\t\tNone\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tindexes = numpy.arange(train_set[0].shape[0])\n",
    "\t\tfor e in range(self.num_epochs) :\n",
    "\t\t\n",
    "\t\t\tchoosen_indexes = numpy.random.choice(indexes, size = self.batch_size, replace = False)\n",
    "\t\t\tx_batch = train_set[0][choosen_indexes]\n",
    "\t\t\ty_batch = train_set[1][choosen_indexes]\n",
    "\n",
    "\t\t\toutput_values, activation_outputs = self.forward_propagation(x_batch)\n",
    "\t\t\tlocal_graidents = self.backward_propagation(y_batch, output_values, activation_outputs)\n",
    "\n",
    "\t\t\tself.weights[0] -= self.learning_rate * (x_batch.T.dot(local_graidents[0]))\n",
    "\t\t\tfor l in range(1, self.n_layers-1):\n",
    "\t\t\t\tdelta_weight = (1/x_batch.shape[0]) * self.learning_rate * activation_outputs[l - 1].T.dot(local_graidents[l])\n",
    "\t\t\t\tself.weights[l] -= delta_weight\n",
    "\t\t\t\tdelta_bias = (1/x_batch.shape[0]) * self.learning_rate * numpy.sum(local_graidents[l])\n",
    "\t\t\t\tself.biases[l] -= delta_bias\n",
    "\n",
    "\t\t\tif val_set is None :\n",
    "\t\t\t\ty_val_pred_prob=self.predict_prob(val_set[0])\n",
    "\t\t\t\tval_cost=self.cross_entropy_loss(y_val_pred_prob, val_set[1])\n",
    "\t\t\ttrain_cost = self.cross_entropy_loss(activation_outputs[self.n_layers - 2], train_set[1])\n",
    "\n",
    "\t\t\tself.training_loss[e] = train_cost\n",
    "\t\t\tif val_set is None :\n",
    "\t\t\t\tself.validation_loss[e] = val_cost\n",
    "\n",
    "\tdef forward_propagation(self, x) :\n",
    "\t\t\"\"\"\n",
    "\t\tPerforms the forward phase\n",
    "\t\tInput Parameters:\n",
    "\t\t\tx - inputs\n",
    "\t\tOutput Parameters:\n",
    "\t\t\toutputs - output values of each layer\n",
    "\t\t\tactivations - output values of each layer after performing activation\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\toutputs = []\n",
    "\t\tactivations = []\n",
    "\t\tfor l in range(self.n_layers - 2) :\n",
    "\t\t\thidden_output = x.dot(self.weights[l]) + self.biases[l]\n",
    "\t\t\thidden_activation_output, _ = self.activation_fuction_with_derivative(hidden_output)\n",
    "\n",
    "\t\t\tx = hidden_activation_output\n",
    "\t\t\toutputs.append(hidden_output)\n",
    "\t\t\tactivations.append(hidden_activation_output)\n",
    "\n",
    "\t\tfinal_output = x.dot(self.weights[self.n_layers - 2]) + self.biases[self.n_layers - 2]\n",
    "\t\tfinal_activation_output, _ = self.softmax(final_output)\n",
    "\t\toutputs.append(final_output)\n",
    "\t\tactivations.append(final_activation_output)\n",
    "\n",
    "\t\treturn outputs, activations\n",
    "\n",
    "\tdef backward_propagation(self, y_true, outputs, activation_outputs) :\n",
    "\t\t\"\"\"\n",
    "\t\tPerforms the backward phase\n",
    "\t\tInput Parameters:\n",
    "\t\t\ty_true - true targets\n",
    "\t\t\tv - outputs after each layer\n",
    "\t\t\ty - outputs after performing activations\n",
    "\t\tOutput Parameters:\n",
    "\t\t\tlocal_gradients : local gradients for each layer\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tlocal_gradients = {}\n",
    "\t\tlast_layer_gradient = activation_outputs[self.n_layers - 2] - y_true\n",
    "\t\tlocal_gradients[self.n_layers - 2] = last_layer_gradient\n",
    "\n",
    "\t\tfor l in range(self.n_layers - 3, -1, -1) :\n",
    "\t\t\tnext_layer_error = local_gradients[l + 1].dot(self.weights[l + 1].T)\n",
    "\t\t\t_, derivative = self.activation_fuction_with_derivative(outputs[l])\n",
    "\t\t\tlocal_gradients[l] = next_layer_error * derivative\n",
    "\n",
    "\t\treturn local_gradients\n",
    "\n",
    "\tdef predict_proba(self, x) :\n",
    "\t\t\"\"\"\n",
    "\t\tPredicts probabilities of targets for given features\n",
    "\t\tInput Parameters :\n",
    "\t\t\tx - features for which targets probabilities are needed\n",
    "\t\tOutput Parameters:\n",
    "\t\t\tprobs - calculated probabilities\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\tprobs, _ = self.forward_propagation(x)\n",
    "\n",
    "\t\treturn probs[self.n_layers - 2]\n",
    "\n",
    "\tdef predict(self, x) :\n",
    "\t\t\"\"\"\n",
    "\t\tPredict targets for given features\n",
    "\t\tInput Parameters :\n",
    "\t\t\tx - features for which targets are needed\n",
    "\t\tOutput Parameters:\n",
    "\t\t\ty - calculated targets\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\tprob = self.predict_proba(x)\n",
    "\t\ty = prob.argmax(axis = 1)\n",
    "\n",
    "\t\treturn y\n",
    "\n",
    "\tdef score(self, x, y) :\n",
    "\t\t\"\"\"\n",
    "\t\tCalculates the score (accuracy) of the model\n",
    "\t\tInput Parameters :\n",
    "\t\t\tx - features for which targets are needed\n",
    "\t\t\ty - actual targets\n",
    "\t\tOutput Parameters :\n",
    "\t\t\taccuracy - accuracy of the model on the provided features and targets\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\ty_pred = self.predict(x)\n",
    "\t\taccuracy = (y == y_pred).mean()\n",
    "\n",
    "\t\treturn accuracy\n",
    "\n",
    "\tdef plot_losses(self) :\n",
    "\t\t\"\"\"\n",
    "\t\tPlot losses from calculated training (and validation) losses\n",
    "\t\tInput Parameters:\n",
    "\t\t\tNone\n",
    "\t\tOutput Parameters:\n",
    "\t\t\tNone\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tmatplotlib.pyplot.plot(self.training_loss, label = 'Training')\n",
    "\t\tmatplotlib.pyplot.plot(self.validation_loss, label = 'Validation')\n",
    "\t\tmatplotlib.pyplot.legend()\n",
    "\t\tmatplotlib.pyplot.grid(True)\n",
    "\t\tmatplotlib.pyplot.ylabel(\"Error\")\n",
    "\t\tmatplotlib.pyplot.xlabel(\"Epochs\")\n",
    "\t\tmatplotlib.pyplot.rc('axes', labelsize = 20)\n",
    "\t\ttitle_text = \"Training and Validation Erros vs Epochs\" + \"\\nfor alpha = \" + str(self.learning_rate) + \", activation = \" + self.activation + \" and weight init = \" + self.weight_init\n",
    "\t\tmatplotlib.pyplot.title(title_text, fontsize = 14)\n",
    "\t\tsave_name = \"l=\" + str(self.learning_rate) +\"_\" + \"a=\" + self.activation + \"_\" + \"w=\" + self.weight_init\n",
    "\t\tmatplotlib.pyplot.savefig(\"Plots/Q2/\" + save_name + \".jpg\")\n",
    "\t\tmatplotlib.pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sklearns(layers, learning_rate, epochs, train_set, test_set, type, name) :\n",
    "\t\"\"\"\n",
    "\tPerforms Multilayer Perceptron using sklearn\n",
    "\tInput Parameters:\n",
    "\t\tlayers - layer sizes\n",
    "\t\tlearning_rate - learning rate for model\n",
    "\t\tepochs - number of iterations\n",
    "\t\ttrain_set - training set\n",
    "\t\ttest_set - testing set\n",
    "\t\ttype - type of activation function to use\n",
    "\t\tname - name of activation function used\n",
    "\t\"\"\"\n",
    "\tmodel = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=layers[1:-1], solver='sgd', activation=type, learning_rate='constant', learning_rate_init=learning_rate, max_iter=epochs)\n",
    "\tmodel.fit(train_set[0], numpy.ravel(train_set[1]))\n",
    "\ttrain_acc = model.score(train_set[0], numpy.ravel(train_set[1]))\n",
    "\ttest_acc = model.score(test_set[0], numpy.ravel(test_set[1]))\n",
    "\tprint(name, \":\", \"Training accuracy:\", train_acc, \"Testing accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_name = \"Datasets/Q2\"\n",
    "x, y = preprocessing(folder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = split_dataset(x, y, 0.7, 0.2, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [784, 256, 128, 64, 32, 1]\n",
    "n_layers = len(layers)\n",
    "activation = 'tanh'\n",
    "learning_rate = 0.08\n",
    "weight_init = 'normal'\n",
    "batch_size = train_set[0].shape[0] // 20\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy :  0.12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MyNeuralNetwork(n_layers, layers, activation, learning_rate, weight_init, batch_size, epochs)\n",
    "model.fit(train_set, val_set)\n",
    "model.plot_losses()\n",
    "testing_accuracy = model.score(test_set[0], test_set[1])\n",
    "\n",
    "print(\"Testing Accuracy : \", testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 784) (3500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELU : Training accuracy: 0.10612244897959183 Testing accuracy: 0.11428571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear : Training accuracy: 0.09959183673469388 Testing accuracy: 0.12\n",
      "Sigmoid : Training accuracy: 0.5346938775510204 Testing accuracy: 0.49714285714285716\n",
      "tanh : Training accuracy: 0.09673469387755101 Testing accuracy: 0.06857142857142857\n"
     ]
    }
   ],
   "source": [
    "solvers = [('relu', 'RELU'), ('identity', 'Linear'), ('logistic', 'Sigmoid'), ('tanh', 'tanh')]\n",
    "for s in solvers:\n",
    "\tsklearns(layers, learning_rate, epochs, train_set, test_set, s[0], s[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
